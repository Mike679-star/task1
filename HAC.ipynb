{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bfe7168",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a077bb0",
   "metadata": {},
   "source": [
    "计算两点之间的距离"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64a17763",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euler_distance(point1, point2):\n",
    "    distance = 0.0\n",
    "    for a, b in zip(point1, point2):\n",
    "        distance += math.pow(a - b, 2)\n",
    "    return math.sqrt(distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffed2386",
   "metadata": {},
   "source": [
    "定义ClusterNode类，来表示聚类树的节点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f29d556",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClusterNode:\n",
    "    def __init__(self, vec, left=None, right=None, distance=-1, id=None, count=1):\n",
    "        \"\"\"\n",
    "        vec: 保存两个数据merge后新的中心\n",
    "        left: 左节点\n",
    "        right: 右节点\n",
    "        distance: 两个节点的距离\n",
    "        id: 保存哪个节点是计算过的\n",
    "        count: 这个节点的叶子节点个数\n",
    "        \"\"\"\n",
    "        self.vec = vec\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.distance = distance\n",
    "        self.id = id\n",
    "        self.count = count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a06931",
   "metadata": {},
   "source": [
    "定义Hierarchical类，传入聚类的个数，并对图像进行HAC聚类处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ee92048",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hierarchical:\n",
    "    def __init__(self, k=1):\n",
    "        assert k > 0\n",
    "        self.k = k\n",
    "        self.labels = None\n",
    "\n",
    "    def fit(self, x):\n",
    "        # 初始化节点各位等于数据的个数\n",
    "        nodes = [ClusterNode(vec=v, id=i) for i, v in enumerate(x)]\n",
    "        distance = {}\n",
    "        point_num, feature_num = np.shape(x)\n",
    "        self.labels = [-1] * point_num\n",
    "        currentclustid = -1\n",
    "        while len(nodes) > self.k:\n",
    "            min_dist = np.inf\n",
    "            # 当前节点的个数\n",
    "            nodes_len = len(nodes)\n",
    "            # 最相似的两个类别\n",
    "            closest_part = None\n",
    "            # 当前节点中两两距离计算，找出最近的两个节点\n",
    "            for i in range(nodes_len - 1):\n",
    "                for j in range(i + 1, nodes_len):\n",
    "                    # 避免重复计算\n",
    "                    d_key = (nodes[i].id, nodes[j].id)\n",
    "                    if d_key not in distance:\n",
    "                        distance[d_key] = euler_distance(nodes[i].vec, nodes[j].vec)\n",
    "                    d = distance[d_key]\n",
    "                    if d < min_dist:\n",
    "                        min_dist = d\n",
    "                        closest_part = (i, j)\n",
    "            part1, part2 = closest_part\n",
    "            node1, node2 = nodes[part1], nodes[part2]\n",
    "            # 将两个节点进行合并,即两个节点所包含的所有数据的平均值\n",
    "            new_vec = [(node1.vec[i] * node1.count + node2.vec[i] * node2.count) / (node1.count + node2.count)\n",
    "                       for i in range(feature_num)]\n",
    "            new_node = ClusterNode(vec=new_vec, left=node1, right=node2, distance=min_dist, id=currentclustid,\n",
    "                                   count=node1.count + node2.count)\n",
    "            currentclustid -= 1\n",
    "            # 删掉这最近的两个节点\n",
    "            del nodes[part2], nodes[part1]\n",
    "            # 把新的节点添加进去\n",
    "            nodes.append(new_node)\n",
    "        # 树建立完成，这里要注意，在示例中是最终凝聚为1个节点，而这里到达所要指定的类别数目即停止，一个node属于一个类别\n",
    "        self.nodes = nodes\n",
    "        # 给每个node以及node包含的数据打上标签\n",
    "        self.calc_label()\n",
    "\n",
    "    def calc_label(self):\n",
    "        # 调取聚类结果\n",
    "        for i, node in enumerate(self.nodes):\n",
    "            self.leaf_traversal(node, i)\n",
    "\n",
    "    def leaf_traversal(self, node: ClusterNode, label):\n",
    "        # 递归遍历叶子结点\n",
    "        if node.left is None and node.right is None:\n",
    "            self.labels[node.id] = label\n",
    "        if node.left:\n",
    "            self.leaf_traversal(node.left, label)\n",
    "        if node.right:\n",
    "            self.leaf_traversal(node.right, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d70821",
   "metadata": {},
   "source": [
    "加载图像，并将图像转换为一维数组，注意读取的是在原图基础上裁剪过后的图片，因为HAC的时间复杂度太高"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1d04ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('cat1_crop.jpg')\n",
    "img_data = img.reshape(-1, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be7a004",
   "metadata": {},
   "source": [
    "初始化聚类树，并进行HAC聚类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61f8203d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:4: RuntimeWarning: overflow encountered in ubyte_scalars\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "hac = Hierarchical(4)\n",
    "hac.fit(img_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f5d32c",
   "metadata": {},
   "source": [
    "对聚类结果进行上色处理，背景变为黑色，前景变为白色"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0cbeee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar = hac.labels[0]\n",
    "for id, label in enumerate(hac.labels):\n",
    "    if label == tar:\n",
    "        img_data[id] = [0, 0, 0]\n",
    "    else:\n",
    "        img_data[id] = [255, 255, 255]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d20a33c",
   "metadata": {},
   "source": [
    "将图片从一维reshape成原始大小，展示结果，并保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f75e70f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_over = img_data.reshape(img.shape)\n",
    "cv2.imshow('Segmented Image', img_over)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.imwrite('cat1_hac.jpg', img_over)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch] *",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
